{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import trimesh\n",
    "import json\n",
    "import numpy as np\n",
    "from munch import *\n",
    "from options import BaseOptions\n",
    "from model import Generator\n",
    "from generate_shapes_and_images import generate, generateImage\n",
    "from render_video import render_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetImages():\n",
    "    def __init__(self) -> None:\n",
    "        torch.random.manual_seed(234)\n",
    "        # torch.random.manual_seed(321)\n",
    "        self.device = \"cuda\"\n",
    "        self.inference_identities = 100\n",
    "\n",
    "        self.opt = BaseOptions().parse()\n",
    "        self.opt.camera.uniform = True\n",
    "        self.opt.model.is_test = True\n",
    "        self.opt.model.freeze_renderer = False\n",
    "        self.opt.rendering.offset_sampling = True\n",
    "        self.opt.rendering.static_viewdirs = True\n",
    "        self.opt.rendering.force_background = True\n",
    "        self.opt.rendering.perturb = 0\n",
    "        self.opt.inference.renderer_output_size = self.opt.model.renderer_spatial_output_dim\n",
    "        self.opt.inference.style_dim = self.opt.model.style_dim\n",
    "        self.opt.inference.project_noise = self.opt.model.project_noise\n",
    "\n",
    "        # User options\n",
    "        self.model_type = 'ffhq' # Whether to load the FFHQ or AFHQ model\n",
    "        self.opt.inference.no_surface_renderings = True # When true, only RGB images will be created\n",
    "        self.opt.inference.fixed_camera_angles = True # When true, each identity will be rendered from a specific set of 13 viewpoints. Otherwise, random views are generated\n",
    "        self.opt.inference.identities = self.inference_identities # Number of identities to generate\n",
    "        self.opt.inference.num_views_per_id = 1 # Number of viewpoints generated per identity. This option is ignored if self.opt.inference.fixed_camera_angles is true.\n",
    "\n",
    "    def main(self):\n",
    "        # main\n",
    "        model_path = self.loadSavedModel()\n",
    "        checkpoint = self.createResultDir(model_path)\n",
    "        \n",
    "        g_ema = self.loadImageGenerationModel(checkpoint)\n",
    "        surface_g_ema = self.loadVolumnRender()\n",
    "        \n",
    "        mean_latent, surface_mean_latent = self.getMeanLatentVector(g_ema)\n",
    "        prepareDatasetPath = \"prepareDataset\"\n",
    "\n",
    "        with open(os.path.join(prepareDatasetPath , \"json\", \"camera_paras.json\"), 'w') as jsonFile:\n",
    "            jsonFile.write(\"[\")\n",
    "        with open(os.path.join(prepareDatasetPath , \"json\", \"sample_z.json\"), 'w') as jsonFile:\n",
    "            jsonFile.write(\"[\")\n",
    "        self.generate(g_ema, surface_g_ema, mean_latent, surface_mean_latent)\n",
    "        with open(os.path.join(prepareDatasetPath , \"json\", \"camera_paras.json\"), 'a') as jsonFile:\n",
    "            jsonFile.write(\"]\")\n",
    "        with open(os.path.join(prepareDatasetPath , \"json\", \"sample_z.json\"), 'a') as jsonFile:\n",
    "            jsonFile.write(\"]\")\n",
    "        \n",
    "        # store json\n",
    "        # with open(os.path.join(prepareDatasetPath , \"json\", \"camera_paras.json\"), 'w') as jsonFile:\n",
    "        #     json.dump(camera_paras_list , jsonFile)\n",
    "        # with open(os.path.join(prepareDatasetPath , \"json\", \"sample_z.json\"), 'w') as jsonFile:\n",
    "        #     json.dump(sample_z_list , jsonFile)\n",
    "\n",
    "        if mean_latent:\n",
    "            for i in range(len(mean_latent)):\n",
    "                mean_latent[i] = mean_latent[i].tolist()\n",
    "        with open(os.path.join(prepareDatasetPath , \"json\", \"mean_latent.json\"), 'w') as jsonFile:\n",
    "            json.dump(mean_latent , jsonFile)\n",
    "        \n",
    "        # self.storeJson(camera_paras_list, os.path.join(prepareDatasetPath , \"json\", \"camera_paras.json\"))\n",
    "        # self.storeJson(sample_z_list, os.path.join(prepareDatasetPath , \"json\", \"sample_z\"))\n",
    "        # self.storeJson(mean_latent, \"mean_latent\")\n",
    "        # self.storeJson(surface_g_ema, \"surface_g_ema\") # None\n",
    "        # self.storeJson(surface_mean_latent, \"surface_mean_latent\") # None\n",
    "        pass\n",
    "\n",
    "    def loadSavedModel(self):\n",
    "        # Load saved model\n",
    "        if self.model_type == 'ffhq':\n",
    "            model_path = 'ffhq1024x1024.pt'\n",
    "            self.opt.model.size = 1024\n",
    "            self.opt.experiment.expname = 'ffhq1024x1024'\n",
    "        else:\n",
    "            self.opt.inference.camera.azim = 0.15\n",
    "            model_path = 'afhq512x512.pt'\n",
    "            self.opt.model.size = 512\n",
    "            self.opt.experiment.expname = 'afhq512x512'\n",
    "        return model_path\n",
    "\n",
    "    def createResultDir(self, model_path):\n",
    "        # Create results directory\n",
    "        result_model_dir = 'final_model'\n",
    "        results_dir_basename = os.path.join(self.opt.inference.results_dir, self.opt.experiment.expname)\n",
    "        self.opt.inference.results_dst_dir = os.path.join(results_dir_basename, result_model_dir)\n",
    "        if self.opt.inference.fixed_camera_angles:\n",
    "            self.opt.inference.results_dst_dir = os.path.join(self.opt.inference.results_dst_dir, 'fixed_angles')\n",
    "        else:\n",
    "            self.opt.inference.results_dst_dir = os.path.join(self.opt.inference.results_dst_dir, 'random_angles')\n",
    "\n",
    "        os.makedirs(self.opt.inference.results_dst_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.opt.inference.results_dst_dir, 'images'), exist_ok=True)\n",
    "        if not self.opt.inference.no_surface_renderings:\n",
    "            os.makedirs(os.path.join(self.opt.inference.results_dst_dir, 'depth_map_meshes'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.opt.inference.results_dst_dir, 'marching_cubes_meshes'), exist_ok=True)\n",
    "\n",
    "        self.opt.inference.camera = self.opt.camera\n",
    "        self.opt.inference.size = self.opt.model.size\n",
    "        checkpoint_path = os.path.join('full_models', model_path)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        return checkpoint\n",
    "    \n",
    "    def loadImageGenerationModel(self, checkpoint):\n",
    "        # Load image generation model\n",
    "        g_ema = Generator(model_opt=self.opt.model, renderer_opt=self.opt.rendering, full_pipeline=True).to(self.device)\n",
    "        self.pretrained_weights_dict = checkpoint[\"g_ema\"]\n",
    "        model_dict = g_ema.state_dict()\n",
    "        for k, v in self.pretrained_weights_dict.items():\n",
    "            if v.size() == model_dict[k].size():\n",
    "                model_dict[k] = v\n",
    "\n",
    "        g_ema.load_state_dict(model_dict)\n",
    "\n",
    "        return g_ema\n",
    "\n",
    "    def loadVolumnRender(self):\n",
    "        # Load a second volume renderer that extracts surfaces at 128x128x128 (or higher) for better surface resolution\n",
    "        if not self.opt.inference.no_surface_renderings:\n",
    "            self.opt['surf_extraction'] = Munch()\n",
    "            self.opt.surf_extraction.rendering = self.opt.rendering\n",
    "            self.opt.surf_extraction.model = self.opt.model.copy()\n",
    "            self.opt.surf_extraction.model.renderer_spatial_output_dim = 128\n",
    "            self.opt.surf_extraction.rendering.N_samples = self.opt.surf_extraction.model.renderer_spatial_output_dim\n",
    "            self.opt.surf_extraction.rendering.return_xyz = True\n",
    "            self.opt.surf_extraction.rendering.return_sdf = True\n",
    "            surface_g_ema = Generator(self.opt.surf_extraction.model, self.opt.surf_extraction.rendering, full_pipeline=False).to(self.device)\n",
    "\n",
    "            # Load weights to surface extractor\n",
    "            surface_extractor_dict = surface_g_ema.state_dict()\n",
    "            for k, v in self.pretrained_weights_dict.items():\n",
    "                if k in surface_extractor_dict.keys() and v.size() == surface_extractor_dict[k].size():\n",
    "                    surface_extractor_dict[k] = v\n",
    "\n",
    "            surface_g_ema.load_state_dict(surface_extractor_dict)\n",
    "        else:\n",
    "            surface_g_ema = None\n",
    "        \n",
    "        return surface_g_ema\n",
    "    \n",
    "    def getMeanLatentVector(self, g_ema):\n",
    "        # Get the mean latent vector for g_ema\n",
    "        if self.opt.inference.truncation_ratio < 1:\n",
    "            with torch.no_grad():\n",
    "                mean_latent = g_ema.mean_latent(self.opt.inference.truncation_mean, self.device)\n",
    "        else:\n",
    "            surface_mean_latent = None\n",
    "\n",
    "        # Get the mean latent vector for surface_g_ema\n",
    "        if not self.opt.inference.no_surface_renderings:\n",
    "            surface_mean_latent = mean_latent[0]\n",
    "        else:\n",
    "            surface_mean_latent = None\n",
    "\n",
    "        return (mean_latent, surface_mean_latent)\n",
    "\n",
    "    def generate(self, g_ema, surface_g_ema, mean_latent, surface_mean_latent):\n",
    "        # locatoin = [0,0]\n",
    "        # generateImage(self.opt.inference, g_ema, self.device, mean_latent)\n",
    "        # generateImage(self.opt.inference, g_ema, surface_g_ema, self.device, mean_latent, surface_mean_latent)\n",
    "        camera_paras_list, sample_z_list = generate(self.opt.inference, g_ema, surface_g_ema, self.device, mean_latent, surface_mean_latent)\n",
    "        # return (camera_paras_list, sample_z_list)\n",
    "        pass\n",
    "        \n",
    "    def storeJson(self, obj, objName):\n",
    "        newpath = './json/'\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "\n",
    "        with open(f'{newpath}{objName}.json', 'w') as j:\n",
    "            json.dump(obj , j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getImages = GetImages()\n",
    "getImages.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
