{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as FT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import subprocess\n",
    "from generate_shapes_and_images import generate\n",
    "\n",
    "\n",
    "\n",
    "from myService.myModel import *\n",
    "from myService.myDataset import MyDataset\n",
    "from myService.myUtils import my_collate\n",
    "from myService.getImages import GetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMain():\n",
    "    def __init__(self):\n",
    "        # config #\n",
    "        self.use_cuda=True\n",
    "        self.dataPath = './result/thumbs'\n",
    "        self.model_save_dir = './result/model'\n",
    "        self.learningRate = 0.01\n",
    "\n",
    "        # set device #\n",
    "        self.device = torch.device(\"cuda\" if (torch.cuda.is_available() & self.use_cuda) else \"cpu\")\n",
    "        print('===== MyMain Info =====')\n",
    "        print(f'device: {self.device}')\n",
    "        print()\n",
    "\n",
    "        # Config Training List #\n",
    "        # Diff Encoders\n",
    "        self.initModel()\n",
    "        self.initLoss()\n",
    "        self.initOptmizer()\n",
    "        self.encoderUsed_list_map = {\n",
    "            \"simpleMLP\": self.model_mlp,\n",
    "            \"CNN\": self.model_cnn,\n",
    "        }\n",
    "\n",
    "    def saveModel(self, model, modelName):\n",
    "        model_path = os.path.join(self.model_save_dir, f'{modelName}.ckpt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f'Saved {modelName} into {self.model_save_dir}...')\n",
    "\n",
    "    def loadModelState(self, model, modelName):\n",
    "        print(f'Loading the trained models {modelName}')\n",
    "        model_path = os.path.join(self.model_save_dir, f'{modelName}.ckpt')\n",
    "        model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    def initModel(self):\n",
    "        self.model_mlp = MLP(n_class=3).to(self.device)\n",
    "        self.model_convNet = ConvNet(n_class=3).to(self.device)\n",
    "        self.model_cnn = CNN().to(self.device)\n",
    "\n",
    "    def initLoss(self):\n",
    "        self.loss = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "\n",
    "    def initOptmizer(self):\n",
    "        self.optimizer = optim.Adam(self.model_cnn.parameters(), lr=self.learningRate)\n",
    "\n",
    "    def getDataLoader(self, batch_size=5, transform =None):\n",
    "        # transform = transforms.Compose([\n",
    "        #         transforms.Resize((28,28)),\n",
    "        #         transforms.ToTensor()\n",
    "        #         ])\n",
    "        \n",
    "        mydataset = MyDataset(transform = transform)\n",
    "        mydata_loader = DataLoader(mydataset, batch_size=batch_size, num_workers=0,  collate_fn = my_collate)\n",
    "        \n",
    "        checkShape = False\n",
    "        if checkShape:\n",
    "            for data in mydata_loader:\n",
    "                print(len(data))\n",
    "                print(data[0].shape)\n",
    "                print(data[1].shape)\n",
    "                break \n",
    "        return mydata_loader\n",
    "\n",
    "    def plot(self, plt_loss_train):\n",
    "        plt.plot(list(range(len(plt_loss_train))), plt_loss_train)\n",
    "        plt.savefig('./result/loss.png')\n",
    "\n",
    "    def DiffTrains(self):\n",
    "        \"\"\"\n",
    "        ===== Training Info =====\n",
    "        Current Pipeline: image_64x64 -(InverseNet)-> z_1x265 (see loss)\n",
    "\n",
    "        ===== Dev Info =====\n",
    "        handle generate image (used comment for above dev)\n",
    "\n",
    "        \"\"\"\n",
    "        # Config Training List #\n",
    "        # Diff Encoders\n",
    "        encoderUsed_list = [\"CNN\"]\n",
    "\n",
    "        # Diff Ways of Loss Function Calculation\n",
    "        lossWeight_list = [\n",
    "            {\n",
    "                \"latent\": 1,\n",
    "                \"camera_para\": 0,\n",
    "                \"image\": 0\n",
    "            }\n",
    "        ]\n",
    "        # lossProcess_list = [[\"latent\", \"camera_para\", \"image\"]]\n",
    "        lossProcess_list = [\n",
    "            [[\"latent\"]],\n",
    "            # [[\"latent\", \"camera_para\", \"image\"]]\n",
    "        ]\n",
    "        lossSwitchMoment_list = [(\"epoch\", 10)]\n",
    "        \n",
    "        # Diff HyperParameter\n",
    "        batchSize_list = [5]\n",
    "        epoch_list = [100]\n",
    "\n",
    "        total_info = {\n",
    "            \"encoderUsed_list\": encoderUsed_list,\n",
    "            \"lossWeight_list\": lossWeight_list,\n",
    "            \"lossProcess_list\": lossProcess_list,\n",
    "            \"lossSwitchMoment_list\": lossSwitchMoment_list,\n",
    "            \"batchSize_list\": batchSize_list,\n",
    "            \"epoch_list\": epoch_list,\n",
    "        }\n",
    "\n",
    "        # Main Loop #\n",
    "        plt_loss_train_info_list = []\n",
    "\n",
    "        # Diff Encoders #\n",
    "        for encoderUsed in encoderUsed_list:\n",
    "\n",
    "            # Diff Ways of Loss Function Calculation #\n",
    "            for lossWeight in lossWeight_list:\n",
    "                for lossProcess in lossProcess_list:\n",
    "                    for lossSwitchMoment in lossSwitchMoment_list:\n",
    "                        \n",
    "                        # Diff HyperParameter #\n",
    "                        for batchSize in batchSize_list:\n",
    "                            for totalEpoch in epoch_list:\n",
    "                                \n",
    "                                training_paras = {\n",
    "                                    \"encoderUsed\": encoderUsed,\n",
    "                                    \"lossWeight\": lossWeight,\n",
    "                                    \"lossProcess\": lossProcess,\n",
    "                                    \"lossSwitchMoment\": lossSwitchMoment,\n",
    "                                    \"batchSize\": batchSize,\n",
    "                                    \"totalEpoch\": totalEpoch\n",
    "                                }\n",
    "                                plt_loss_train = self.train(**training_paras)\n",
    "\n",
    "                                for i in range(len(plt_loss_train)):\n",
    "                                    plt_loss_train[i] = plt_loss_train[i].cpu().tolist()\n",
    "\n",
    "                                plt_loss_train_info = {\n",
    "                                    **training_paras,\n",
    "                                    \"plt_loss_train\": plt_loss_train,\n",
    "                                }\n",
    "                                plt_loss_train_info_list.append(plt_loss_train_info)\n",
    "                            # for epoch_list end\n",
    "\n",
    "        with open('result/plt_loss_train_info_list.json', 'w') as f:\n",
    "            json.dump(plt_loss_train_info_list, f)\n",
    "        with open('result/total_info.json', 'w') as f:\n",
    "            json.dump(total_info, f)\n",
    "\n",
    "        return (plt_loss_train_info_list, total_info)\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        encoderUsed,\n",
    "        lossWeight,\n",
    "        lossProcess,\n",
    "        lossSwitchMoment,\n",
    "        batchSize,\n",
    "        totalEpoch\n",
    "    ):\n",
    "        \"\"\"\n",
    "        config\n",
    "\n",
    "        \"\"\"\n",
    "        encoder = self.encoderUsed_list_map[encoderUsed]\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize((28,28)),\n",
    "                transforms.ToTensor()\n",
    "                ])\n",
    "        dataLoader = self.getDataLoader(batch_size=batchSize, transform=transform)\n",
    "\n",
    "        print('===== Training Info =====')\n",
    "        plt_loss_train=[]\n",
    "        for epochIdx in range(totalEpoch):\n",
    "\n",
    "            CurrentEpochLossFunctionIdx = int((epochIdx / lossSwitchMoment[1]) % len(lossProcess))\n",
    "            CurrentEpochLossFunction_list = lossProcess[CurrentEpochLossFunctionIdx]\n",
    "            \n",
    "            encoder.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(dataLoader):\n",
    "\n",
    "                data = torch.squeeze(data)\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                \"\"\"\n",
    "                get predict result\n",
    "\n",
    "                \"\"\"                \n",
    "                latent_predict = encoder(data)\n",
    "                # generated_image = generate(self.opt.inference, g_ema, surface_g_ema, self.device, mean_latent, surface_mean_latent)\n",
    "                \n",
    "                \"\"\"\n",
    "                calculate loss\n",
    "\n",
    "                \"\"\"\n",
    "                latent_loss = self.loss(latent_predict,target)  \n",
    "                \n",
    "                if \"latent\" in CurrentEpochLossFunction_list: \n",
    "                    train_loss += latent_loss*lossWeight[\"latent\"]\n",
    "                # if \"camera_para\" in CurrentEpochLossFunction_list: \n",
    "                #     train_loss += camera_para_loss*lossWeight[\"camera_para\"]\n",
    "                # if \"image\" in CurrentEpochLossFunction_list: \n",
    "                #     train_loss += image_loss*lossWeight[\"image\"]\n",
    "\n",
    "                # surface_mean_latent = None\n",
    "                # mean_latent = None\n",
    "\n",
    "                \"\"\"\n",
    "                update parameters\n",
    "                \n",
    "                \"\"\"\n",
    "                latent_loss.backward()\n",
    "                self.optimizer.step()\n",
    "            # for dataLoader end\n",
    "\n",
    "            train_loss /= len(dataLoader.dataset)\n",
    "            plt_loss_train.append(train_loss)\n",
    "        \n",
    "            if epochIdx % 10 ==0:\n",
    "                print(f'{encoderUsed}[epochIdx: {epochIdx+1}/{totalEpoch}], Average loss (Train):{train_loss}')\n",
    "        # for totalEpoch end \n",
    "\n",
    "        print(f'{encoderUsed}[epochIdx: {epochIdx+1}/{totalEpoch}], Average loss (Train):{train_loss}')\n",
    "        print('training done.')\n",
    "        print()\n",
    "\n",
    "        return plt_loss_train\n",
    "\n",
    "    def main(self):\n",
    "        # self.initModel()\n",
    "        # self.initLoss()\n",
    "        # self.initOptmizer()\n",
    "        # plt_loss_train_info_list, total_info = self.DiffTrains()\n",
    "        # self.plot(plt_loss_train_info_list)\n",
    "        \n",
    "        plt_loss_train_info_list, total_info = self.DiffTrains()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMain = MyMain()\n",
    "myMain.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
